<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>Final Project Paper Examples</title>
    <link rel="stylesheet" href="./css/master.css">
  </head>
  <body>
    <div class="contentContainer">
      <div class="content">
        <h1>Examples of Final Project Papers</h1>
        <h3>Some thoughts to consider as you write:</h3>
        <ul>
          <li>What was your intention for your project?</li>
          <li>Where did the idea come from?</li>
          <li>Was this inspired by anything in particular?</li>
          <li>Do you think your ideas are clear in your final project?</li>
          <li>Was there anything unexpected that came up over the course of making your project?</li>
          <li>Do you see a connection or relationship to any other projects you made in the course?</li>
          <li>Do you see a connection or relationship to any other art/artists?</li>
        </ul>
        <hr>
        <div class="">
          <h3>Human Light Show</h3>
          <p>
This project was originally inspired by a dance performance by a group named
Wrecking Orchestra which performed using suited covered in led strips that turned on
and off in sync with music. Our group decided to create a similar suit with LEDs that
would be controlled by a remote. This would allow the user to perform while someone
else handled the lighting effects of the suit for them. The remote control also allowed
us to program more effects than were present in Wrecking Orchestra’s suits.
At the start of the project our goals were to improve upon the original suit
however plans changed as the cost of materials were brought into consideration as well
as a limited time frame. We thought about using neo pixels or RGB LEDs but eventually
decided on normal LEDs due to cost and power restrictions. There were also many
different options we considered using to control the suit. We thought about using the
touch screen in our kit to allow the wearer of the suit to tap the screen in order to
change the LED effects but eventually discarded the idea because it would require the
use of multiple Arduinos which would complicate our design. We also considered using
the joystick to control which LEDs were lit on the suit by moving it in different directions
to change which part of the suit turned on but move away from the idea due to the
possibility of inaccurate readings. The next choice was to use buttons to turn the LEDs
on and off and eventually evolved to the remote because it allowed us to use multiple
buttons with one device.
From this point we divided tasks amongst the group with Gabe creating the
overall design and circuit of the suit, Jeff building the circuits, and I was tasked with
writing the code to control the suit. We mostly ran into problems with building the
circuit due to problems powering the large number of LEDs we were planning to use.
We were advised to use transistors in order to limit the amount of power running
through the circuit but ran into problems implementing them into our existing circuit
initially. This was probably the most difficult part of the process because we weren’t
familiar with them but eventually we were able to figure out how to incorporate them.
Overall The end product turnout out very well and we learned a lot by going
through the process of making it. I think it also really fits in with today’s culture of
wearable technology. Many people use wearable technology for convenience and ease
of access to a multitude of services. Our suit is more focused on the artistic side
however and would allow performers to dance and express themselves in a unique and
creative way. The suit also reminded me of things we discussed in class such as being a
cyborg and extending oneself. Technology is increasingly becoming a bigger part of our
everyday lives and I believe there will come a point in time where we will no longer be
able to live without it. It will become more and more ingrained in us and in the future, it
could potentially even be common for people to have technology implanted into them.
This could enhance our abilities as humans but hopefully doesn’t take over our lives or
lead to our downfall.</p>
        </div>
        <hr>
        <br>
        <div class="">
          <h3>ART 150 Final Project</h3>
          <p>For my final project, I decided to create a game utilizing both Processing and the
Arduino. I decided on this because I believe my greater skills lie in software rather than
hardware, and I wanted to challenge myself to code something I haven’t attempted before and try
my hand at communication between the Arduino and Processing. Trying to think of a concept for
the game took some time, but I knew I wanted interactivity to be at the center of it. I ultimately
decided on the basis on my game being different actions with sensors causing different
manipulations to happen to the items in Processing, and the player has to figure out which
actions will help them complete the game. To do this, I utilized the Ultrasonic Sensor and the
Touch Sensor (MPR121). Different distances detected by the Ultrasonic Sensor would cause
different things to happen to the shapes in the level, and different ranges of outputs touched on
the MPR121 would cause different things to happen to the shapes in the level. For example, in
one of my levels, different distances detected by the Ultrasonic Sensor would cause the opacity
of the shapes in the level to change, and the different ranges touched on the MPR121 would
cause the shapes to move.
Now that I had the interactivity down, I had to give these actions a purpose. Manipulating
shapes using sensors is fun, but isn’t really a game. I decided on hiding four different numbers
underneath of the shapes and having the player have to figure out which actions would reveal
these numbers to them. The user would then enter these numbers into a 4X4 keypad, then they
would win the game. I felt this was still too easy though, so I decided to give the numbers an
order, and the player has to not only figure out how to reveal the numbers, but figure out what
order they need to be in as well. This not only adds a layer of complexity, but also opens a
possible competitive element to the game as well. Two players could each have their own set up,
and see who could both reveal their numbers and enter the code in the correct order first. I felt I
now had a complete game idea and could move on to different designs for the levels.
Ultimately, I was only able to implement one extra level, but ideally the game would
have many different levels, utilizing a number of different sensors. I believe with the framework
I have set up, creating more levels with different sensors would be relatively simple. The hardest
part was getting the first level to work, after that implementing the second level took
significantly less time. For my second level, I utilized a different shape with different colors, and
instead of having the two sensors do two different things, I instead had them both manipulate the
size of the shapes, so it was more confusing as to which action needed to be done to be able to
reveal the numbers. From here I believe there are endless level possibilities and it would
definitely be fun to go back in and try to create more.
Overall, this project was both very fun and very challenging to do. The most challenging
part was figuring out how the Arduino and Processing communicated. Once I got that figured out
and objects were being manipulated, creating the levels was really fun to experiment with. I’ve
never built a non-command line game before and being able to utilize the skills I have learned in
this class to build my first one was a really nice way to wrap up the semester. I’m excited to
continue to experiment with Arduino communication outside of this class and continue to learn
more!</p>
        </div>
        <hr>
        <br>
        <div class="">
          <h3>Final</h3>
          <p>I decided to re-use the Processing sketch I have made at the beginning of the semester and build off it for my final project. I realized I really appreciated the possibility for interactive experiences of Processing. I thought it would be a steep but rewarding learning curve to utilize an Xbox360 kinect to enhance the interactive aspect of my sketch.

I have always loved interactive design and projections. I wondered how one might create a projection that others can interact and have fun with because I personally really like the idea of a viewer becoming an essential factor of a projection, and I like the idea of being able to influence and be influenced by one’s environment in such way. I specifically remember seeing the piece “Being Not Truthful Always Works Against Me” by Stefan Sagmeister and Ralph Ammer at the Art Institute several times and how it made me feel/wonder how such projections are made. “Being Not Truthful Always Works Against Me” is “is comprised of those words digitally woven into a projected spiderweb. As a viewer passes in front of the work, a sensor captures the movement, and the web begins to break down, resulting in its eventual destruction and dissolution. However, when the viewer has gone, the web reconstructs itself time and again, playfully mimicking the regenerating power of an actual spider through digital means” (Art Institute of Chicago).

My idea stemmed from a long afternoon of Instagram research on interactive art. From that “Instagram research” I discovered the existence of node-based programs that allow people to create interactive projections. TouchDesigned specifically caught my attention because I really appreciated what people have created with it­; I thought the work was very visually appealing. I learned that similar projects can be completed using Processing and an Xbox Kinect, which is something I never expected a gaming device to be used for (art of that sort).
I wanted to essentially make a more complex version of my Processing sketch; I thought that instead of the sketch reacting to mouseX and mouseY coordinates, it reacts in a similar way by reading the proximity and movement of the viewer. My intention for the projection was to make it aesthetically pleasing and interactive.

I watched Daniel Shiffman’s videos on Processing and Kinect, and it all seemed much simpler than it is. I tried looking up examples of sketches other people have done with the Kinect v1 and Processing and unfortunately found less information about it than I thought I might find. The frustrating aspect of people sharing the visuals they’ve made using both Processing and a Kinect was that a lot of them didn’t post the code for them, which only made learning about how to use the two together more difficult. Another issue was that a lot of the code I did find was compatible with Kinect v2 and not v1. In the end I realized my idea was beyond my capabilities and time frame, so I settled for something simpler (but still rewarding).</p>
        </div>
      </div>
    </div>
  </body>
</html>
